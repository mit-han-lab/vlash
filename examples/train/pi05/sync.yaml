# VLASH Training Configuration for PI05 (Synchronous Baseline)
# Standard training without temporal delay - assumes instant inference

# Policy configuration
policy:
  type: pi05                          # Policy architecture type
  pretrained_path: lerobot/pi05_base  # HuggingFace model path for pretrained weights
  push_to_hub: false                  # Whether to push trained model to HuggingFace Hub
  dtype: bfloat16                     # Model precision (bfloat16 for memory efficiency)
  device: cuda                        # Training device

# Dataset configuration
dataset:
  repo_id:                            # HuggingFace dataset repository ID (required)
  video_backend: torchcodec           # Video decoding backend

# Training parameters
output_dir: outputs/train/pi05        # Directory to save outputs and checkpoints
job_name: pi05                        # Job name for logging and identification
batch_size: 8                         # Number of samples per training step
steps: 50000                          # Total number of training steps
num_workers: 4                        # DataLoader worker processes
seed: 1000                            # Random seed for reproducibility

# Optimizer configuration
use_policy_training_preset: false     # Use custom optimizer instead of policy defaults
optimizer:
  type: adamw                         # AdamW optimizer with weight decay
  lr: 5.0e-5                          # Learning rate
  betas: [0.9, 0.95]                  # Adam beta parameters
  weight_decay: 1.0e-10               # L2 regularization strength

# Learning rate scheduler
scheduler:
  type: cosine_decay_with_warmup      # Cosine annealing with linear warmup
  num_warmup_steps: 1000              # Steps to linearly increase LR from 0
  peak_lr: 5.0e-5                     # Maximum learning rate after warmup
  decay_lr: 2.5e-6                    # Final learning rate after decay
  num_decay_steps: 50000              # Steps for cosine decay phase

# Checkpointing
save_checkpoint: true                 # Enable checkpoint saving
save_freq: 10000                      # Save checkpoint every N steps
eval_freq: 10000                      # Run evaluation every N steps

# Logging
log_freq: 200                         # Log metrics every N steps
wandb:
  enable: true                        # Enable Weights & Biases logging
  project: vlash                      # W&B project name
  entity: null                        # W&B team/user (null for default)

# No temporal delay - standard synchronous training baseline
max_delay_steps: 0
